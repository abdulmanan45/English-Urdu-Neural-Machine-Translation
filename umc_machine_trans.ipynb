{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T11:14:30.283833Z",
     "iopub.status.busy": "2024-11-17T11:14:30.282999Z",
     "iopub.status.idle": "2024-11-17T11:14:58.156905Z",
     "shell.execute_reply": "2024-11-17T11:14:58.155599Z",
     "shell.execute_reply.started": "2024-11-17T11:14:30.283797Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sacrebleu\n",
      "  Downloading sacrebleu-2.4.3-py3-none-any.whl.metadata (51 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting portalocker (from sacrebleu)\n",
      "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (2024.5.15)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (1.26.4)\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.4.6)\n",
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (5.3.0)\n",
      "Downloading sacrebleu-2.4.3-py3-none-any.whl (103 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.0/104.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: portalocker, sacrebleu\n",
      "Successfully installed portalocker-2.10.1 sacrebleu-2.4.3\n",
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.2.4)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.26.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\n",
      "Building wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=7f830fea30507652349e8cca58211b34496516c23ad6d241f723e779de4a3d0e\n",
      "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: rouge_score\n",
      "Successfully installed rouge_score-0.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install sacrebleu\n",
    "!pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-17T11:14:58.159714Z",
     "iopub.status.busy": "2024-11-17T11:14:58.159378Z",
     "iopub.status.idle": "2024-11-17T11:15:03.678962Z",
     "shell.execute_reply": "2024-11-17T11:15:03.678118Z",
     "shell.execute_reply.started": "2024-11-17T11:14:58.159679Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(178) LOG(INFO) Running command: --input=/kaggle/working/UMC005_ur_text.txt --model_prefix=UMC005_ur --character_coverage=1.0 --user_defined_symbols= --vocab_size=3000\n",
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: /kaggle/working/UMC005_ur_text.txt\n",
      "  input_format: \n",
      "  model_prefix: UMC005_ur\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 3000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(353) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(185) LOG(INFO) Loading corpus: /kaggle/working/UMC005_ur_text.txt\n",
      "trainer_interface.cc(409) LOG(INFO) Loaded all 7400 sentences\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(430) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(539) LOG(INFO) all chars count=768601\n",
      "trainer_interface.cc(560) LOG(INFO) Alphabet size=62\n",
      "trainer_interface.cc(561) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(592) LOG(INFO) Done! preprocessed 7400 sentences.\n",
      "unigram_model_trainer.cc(265) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(269) LOG(INFO) Extracting frequent sub strings... node_num=414743\n",
      "unigram_model_trainer.cc(312) LOG(INFO) Initialized 8061 seed sentencepieces\n",
      "trainer_interface.cc(598) LOG(INFO) Tokenizing input sentences with whitespace: 7400\n",
      "trainer_interface.cc(609) LOG(INFO) Done! 6876\n",
      "unigram_model_trainer.cc(602) LOG(INFO) Using 6876 sentences for EM training\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=4760 obj=8.80265 num_tokens=13203 num_tokens/piece=2.77374\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=3654 obj=7.72232 num_tokens=13318 num_tokens/piece=3.64477\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=3203 obj=7.61845 num_tokens=13409 num_tokens/piece=4.18639\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=3171 obj=7.58879 num_tokens=13509 num_tokens/piece=4.26017\n",
      "trainer_interface.cc(687) LOG(INFO) Saving model: UMC005_ur.model\n",
      "trainer_interface.cc(699) LOG(INFO) Saving vocabs: UMC005_ur.vocab\n",
      "sentencepiece_trainer.cc(178) LOG(INFO) Running command: --input=/kaggle/working/UMC005_en_text.txt --model_prefix=UMC005_en --character_coverage=1.0 --user_defined_symbols= --vocab_size=4000\n",
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: /kaggle/working/UMC005_en_text.txt\n",
      "  input_format: \n",
      "  model_prefix: UMC005_en\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 4000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(353) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(185) LOG(INFO) Loading corpus: /kaggle/working/UMC005_en_text.txt\n",
      "trainer_interface.cc(409) LOG(INFO) Loaded all 7400 sentences\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(430) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(539) LOG(INFO) all chars count=896332\n",
      "trainer_interface.cc(560) LOG(INFO) Alphabet size=62\n",
      "trainer_interface.cc(561) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(592) LOG(INFO) Done! preprocessed 7400 sentences.\n",
      "unigram_model_trainer.cc(265) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(269) LOG(INFO) Extracting frequent sub strings... node_num=480867\n",
      "unigram_model_trainer.cc(312) LOG(INFO) Initialized 12340 seed sentencepieces\n",
      "trainer_interface.cc(598) LOG(INFO) Tokenizing input sentences with whitespace: 7400\n",
      "trainer_interface.cc(609) LOG(INFO) Done! 6283\n",
      "unigram_model_trainer.cc(602) LOG(INFO) Using 6283 sentences for EM training\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=5574 obj=9.50436 num_tokens=12074 num_tokens/piece=2.16613\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=4302 obj=7.95926 num_tokens=12337 num_tokens/piece=2.86774\n",
      "trainer_interface.cc(687) LOG(INFO) Saving model: UMC005_en.model\n",
      "trainer_interface.cc(699) LOG(INFO) Saving vocabs: UMC005_en.vocab\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "import sacrebleu\n",
    "import sentencepiece as spm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)\n",
    "\n",
    "SRC = \"en\"\n",
    "TRG = \"ur\"\n",
    "\n",
    "# Function to read UMC005 dataset\n",
    "def read_umc005_data(src_file, trg_file):\n",
    "    with open(src_file, 'r', encoding='utf-8') as f_src, open(trg_file, 'r', encoding='utf-8') as f_trg:\n",
    "        src_lines = f_src.readlines()\n",
    "        trg_lines = f_trg.readlines()\n",
    "    return list(zip([line.strip() for line in src_lines], [line.strip() for line in trg_lines]))\n",
    "\n",
    "# Load UMC005 dataset\n",
    "train_src = \"/kaggle/input/umc005-english-urdu-parallel-corpus/bible/train.en\"\n",
    "train_trg = \"/kaggle/input/umc005-english-urdu-parallel-corpus/bible/train.ur\"\n",
    "valid_src = \"/kaggle/input/umc005-english-urdu-parallel-corpus/bible/dev.en\"\n",
    "valid_trg = \"/kaggle/input/umc005-english-urdu-parallel-corpus/bible/dev.ur\"\n",
    "test_src = \"/kaggle/input/umc005-english-urdu-parallel-corpus/bible/test.en\"\n",
    "test_trg = \"/kaggle/input/umc005-english-urdu-parallel-corpus/bible/test.ur\"\n",
    "\n",
    "train_set = read_umc005_data(train_src, train_trg)\n",
    "valid_set = read_umc005_data(valid_src, valid_trg)\n",
    "test_set = read_umc005_data(test_src, test_trg)\n",
    "\n",
    "# Save text files for SentencePiece training\n",
    "with open(\"/kaggle/working/UMC005_ur_text.txt\", \"w\", encoding='utf-8') as f_ur:\n",
    "    for pair in train_set:\n",
    "        f_ur.write(pair[1] + '\\n')\n",
    "\n",
    "with open(\"/kaggle/working/UMC005_en_text.txt\", \"w\", encoding='utf-8') as f_en:\n",
    "    for pair in train_set:\n",
    "        f_en.write(pair[0] + '\\n')\n",
    "\n",
    "# Adjust vocabulary sizes for smaller dataset\n",
    "ur_vocab_size = 3000  \n",
    "en_vocab_size = 4000\n",
    "vocab_sizes = {\"en\": en_vocab_size, \"ur\": ur_vocab_size}\n",
    "\n",
    "# Train SentencePiece models\n",
    "spm.SentencePieceTrainer.train(\n",
    "    f'--input=/kaggle/working/UMC005_ur_text.txt --model_prefix=UMC005_ur --character_coverage=1.0 --user_defined_symbols= --vocab_size={ur_vocab_size}')\n",
    "spm.SentencePieceTrainer.train(\n",
    "    f'--input=/kaggle/working/UMC005_en_text.txt --model_prefix=UMC005_en --character_coverage=1.0 --user_defined_symbols= --vocab_size={en_vocab_size}')\n",
    "\n",
    "\n",
    "# Load SentencePiece models\n",
    "ur_sp = spm.SentencePieceProcessor()\n",
    "ur_sp.load('/kaggle/working/UMC005_ur.model')\n",
    "en_sp = spm.SentencePieceProcessor()\n",
    "en_sp.load('/kaggle/working/UMC005_en.model')\n",
    "\n",
    "tokenizers = {\"en\": en_sp.encode_as_ids, \"ur\": ur_sp.encode_as_ids}\n",
    "detokenizers = {\"en\": en_sp.decode_ids, \"ur\": ur_sp.decode_ids}\n",
    "\n",
    "# Special tokens\n",
    "UNK, BOS, EOS, PAD = 0, 1, 2, 3\n",
    "\n",
    "# Adjust maximum sequence length for Urdu-English translation\n",
    "max_seq_len = 100  # High as religious texts might have longer sentences\n",
    "\n",
    "def tokenize_dataset(dataset):\n",
    "    'tokenize a dataset and add [BOS] and [EOS] to the beginning and end of the sentences'\n",
    "    return [(torch.tensor([BOS]+tokenizers[SRC](src_text)[0:max_seq_len-2]+[EOS]),\n",
    "             torch.tensor([BOS]+tokenizers[TRG](trg_text)[0:max_seq_len-2]+[EOS]))\n",
    "            for src_text, trg_text in dataset]\n",
    "\n",
    "train_tokenized = tokenize_dataset(train_set)\n",
    "valid_tokenized = tokenize_dataset(valid_set)\n",
    "test_tokenized = tokenize_dataset(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T11:15:03.680548Z",
     "iopub.status.busy": "2024-11-17T11:15:03.680148Z",
     "iopub.status.idle": "2024-11-17T11:15:03.692432Z",
     "shell.execute_reply": "2024-11-17T11:15:03.691504Z",
     "shell.execute_reply.started": "2024-11-17T11:15:03.680517Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "def pad_sequence(batch):\n",
    "    src_seqs = [src for src, trg in batch]\n",
    "    trg_seqs = [trg for src, trg in batch]\n",
    "    src_padded = torch.nn.utils.rnn.pad_sequence(src_seqs, batch_first=True, padding_value=PAD)\n",
    "    trg_padded = torch.nn.utils.rnn.pad_sequence(trg_seqs, batch_first=True, padding_value=PAD)\n",
    "    return src_padded, trg_padded\n",
    "\n",
    "batch_size = 32  # Reduced due to smaller dataset\n",
    "\n",
    "class Dataloaders:\n",
    "    def __init__(self):\n",
    "        self.train_dataset = TranslationDataset(train_tokenized)\n",
    "        self.valid_dataset = TranslationDataset(valid_tokenized)\n",
    "        self.test_dataset = TranslationDataset(test_tokenized)\n",
    "        \n",
    "        self.train_loader = torch.utils.data.DataLoader(\n",
    "            self.train_dataset, batch_size=batch_size, shuffle=True, collate_fn=pad_sequence)\n",
    "        self.test_loader = torch.utils.data.DataLoader(\n",
    "            self.test_dataset, batch_size=batch_size, shuffle=True, collate_fn=pad_sequence)\n",
    "        self.valid_loader = torch.utils.data.DataLoader(\n",
    "            self.valid_dataset, batch_size=batch_size, shuffle=True, collate_fn=pad_sequence)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T11:15:03.695156Z",
     "iopub.status.busy": "2024-11-17T11:15:03.694812Z",
     "iopub.status.idle": "2024-11-17T11:15:03.742777Z",
     "shell.execute_reply": "2024-11-17T11:15:03.741802Z",
     "shell.execute_reply.started": "2024-11-17T11:15:03.695124Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_embed, dropout=0.0):\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_embed % h == 0\n",
    "        self.d_k = d_embed//h\n",
    "        self.d_embed = d_embed\n",
    "        self.h = h\n",
    "        self.WQ = nn.Linear(d_embed, d_embed)\n",
    "        self.WK = nn.Linear(d_embed, d_embed)\n",
    "        self.WV = nn.Linear(d_embed, d_embed)\n",
    "        self.linear = nn.Linear(d_embed, d_embed)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # Store attention weights for visualization\n",
    "        self.attention_weights = None\n",
    "\n",
    "    def forward(self, x_query, x_key, x_value, mask=None):\n",
    "        nbatch = x_query.size(0)\n",
    "        query = self.WQ(x_query).view(nbatch, -1, self.h, self.d_k).transpose(1,2)\n",
    "        key = self.WK(x_key).view(nbatch, -1, self.h, self.d_k).transpose(1,2)\n",
    "        value = self.WV(x_value).view(nbatch, -1, self.h, self.d_k).transpose(1,2)\n",
    "        \n",
    "        scores = torch.matmul(query, key.transpose(-2, -1))/math.sqrt(self.d_k)\n",
    "        \n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask, float('-inf'))\n",
    "        \n",
    "        # Store attention weights for visualization\n",
    "        self.attention_weights = F.softmax(scores, dim=-1)\n",
    "        p_atten = self.dropout(self.attention_weights)\n",
    "        \n",
    "        x = torch.matmul(p_atten, value)\n",
    "        x = x.transpose(1, 2).contiguous().view(nbatch, -1, self.d_embed)\n",
    "        return self.linear(x)\n",
    "\n",
    "def visualize_attention(model, src_sentence, trg_sentence, tokenizers, device=DEVICE):\n",
    "    \"\"\"\n",
    "    Visualize attention weights for a given source and target sentence pair\n",
    "    \"\"\"\n",
    "    # Tokenize input sentences\n",
    "    src_tokens = [en_sp.decode_pieces([en_sp.id_to_piece(id)]) for id in tokenizers[\"en\"](src_sentence)]\n",
    "    trg_tokens = [ur_sp.decode_pieces([ur_sp.id_to_piece(id)]) for id in tokenizers[\"ur\"](trg_sentence)]\n",
    "    \n",
    "    # Prepare input tensors\n",
    "    src_ids = torch.tensor([[BOS] + tokenizers[\"en\"](src_sentence) + [EOS]]).to(device)\n",
    "    trg_ids = torch.tensor([[BOS] + tokenizers[\"ur\"](trg_sentence) + [EOS]]).to(device)\n",
    "    \n",
    "    # Create masks\n",
    "    src_pad_mask = (src_ids == PAD).unsqueeze(1).unsqueeze(2)\n",
    "    trg_pad_mask = (trg_ids == PAD).unsqueeze(1).unsqueeze(2)\n",
    "    \n",
    "    # Forward pass\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Get encoder output and store attention weights\n",
    "        encoder_output = model.encoder(src_ids, src_pad_mask)\n",
    "        decoder_output = model.decoder(encoder_output, src_pad_mask, trg_ids, trg_pad_mask)\n",
    "        \n",
    "        # Get attention weights from the last decoder layer\n",
    "        attention_weights = model.decoder.decoder_blocks[-1].atten2.attention_weights[0]  # Get weights for first batch\n",
    "        \n",
    "        # Average attention weights across heads\n",
    "        attention_weights = attention_weights.mean(dim=0).cpu().numpy()\n",
    "    \n",
    "    # Create attention visualization\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(attention_weights[:len(trg_tokens), :len(src_tokens)],\n",
    "                xticklabels=src_tokens,\n",
    "                yticklabels=trg_tokens,\n",
    "                cmap='viridis',\n",
    "                square=True)\n",
    "    plt.xlabel('English Words')\n",
    "    plt.ylabel('Urdu Words')\n",
    "    plt.title('Attention Weights Visualization')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    return plt\n",
    "\n",
    "def translate_with_attention(model, sentence, tokenizers, max_len=50, device=DEVICE):\n",
    "    \"\"\"\n",
    "    Translate a sentence and return both translation and attention weights\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    src_ids = torch.tensor([[BOS] + tokenizers[\"en\"](sentence) + [EOS]]).to(device)\n",
    "    src_pad_mask = (src_ids == PAD).unsqueeze(1).unsqueeze(2)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        encoder_output = model.encoder(src_ids, src_pad_mask)\n",
    "        \n",
    "        # Initialize target sequence with BOS token\n",
    "        trg_ids = torch.tensor([[BOS]]).to(device)\n",
    "        \n",
    "        for _ in range(max_len):\n",
    "            trg_pad_mask = (trg_ids == PAD).unsqueeze(1).unsqueeze(2)\n",
    "            output = model.decoder(encoder_output, src_pad_mask, trg_ids, trg_pad_mask)\n",
    "            next_token = output[:, -1:].argmax(dim=-1)\n",
    "            trg_ids = torch.cat([trg_ids, next_token], dim=1)\n",
    "            \n",
    "            if next_token.item() == EOS:\n",
    "                break\n",
    "        \n",
    "        # Get attention weights from the last layer\n",
    "        attention_weights = model.decoder.decoder_blocks[-1].atten2.attention_weights[0]\n",
    "        \n",
    "    # Decode the translation\n",
    "    translation = detokenizers[\"ur\"](trg_ids[0].cpu().tolist()[1:-1])\n",
    "    return translation, attention_weights.mean(dim=0).cpu().numpy()\n",
    "\n",
    "\n",
    "class ResidualConnection(nn.Module):\n",
    "  '''residual connection: x + dropout(sublayer(layernorm(x))) '''\n",
    "  def __init__(self, dim, dropout):\n",
    "      super().__init__()\n",
    "      self.drop = nn.Dropout(dropout)\n",
    "      self.norm = nn.LayerNorm(dim)\n",
    "\n",
    "  def forward(self, x, sublayer):\n",
    "      return x + self.drop(sublayer(self.norm(x)))\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    '''Encoder = token embedding + positional embedding -> a stack of N EncoderBlock -> layer norm'''\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.d_embed = config.d_embed\n",
    "        self.tok_embed = nn.Embedding(config.encoder_vocab_size, config.d_embed) \n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, config.max_seq_len, config.d_embed)) \n",
    "        self.encoder_blocks = nn.ModuleList([EncoderBlock(config) for _ in range(config.N_encoder)])\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "        self.norm = nn.LayerNorm(config.d_embed)\n",
    "\n",
    "    def forward(self, input, mask=None):\n",
    "        x = self.tok_embed(input)\n",
    "        x_pos = self.pos_embed[:, :x.size(1), :]\n",
    "        x = self.dropout(x + x_pos)\n",
    "        for layer in self.encoder_blocks:\n",
    "            x = layer(x, mask)\n",
    "        return self.norm(x)\n",
    "\n",
    "\n",
    "class EncoderBlock(nn.Module):\n",
    "    '''EncoderBlock: self-attention -> position-wise fully connected feed-forward layer'''\n",
    "    def __init__(self, config):\n",
    "        super(EncoderBlock, self).__init__()\n",
    "        self.atten = MultiHeadedAttention(config.h, config.d_embed, config.dropout)\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(config.d_embed, config.d_ff),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(config.dropout),\n",
    "            nn.Linear(config.d_ff, config.d_embed)\n",
    "        )\n",
    "        self.residual1 = ResidualConnection(config.d_embed, config.dropout)\n",
    "        self.residual2 = ResidualConnection(config.d_embed, config.dropout)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        # self-attention\n",
    "        x = self.residual1(x, lambda x: self.atten(x, x, x, mask=mask))\n",
    "        # position-wise fully connected feed-forward layer\n",
    "        return self.residual2(x, self.feed_forward)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    '''Decoder = token embedding + positional embedding -> a stack of N DecoderBlock -> fully-connected layer'''\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.d_embed = config.d_embed\n",
    "        self.tok_embed = nn.Embedding(config.decoder_vocab_size, config.d_embed)\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, config.max_seq_len, config.d_embed)) \n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "        self.decoder_blocks = nn.ModuleList([DecoderBlock(config) for _ in range(config.N_decoder)])\n",
    "        self.norm = nn.LayerNorm(config.d_embed)\n",
    "        self.linear = nn.Linear(config.d_embed, config.decoder_vocab_size)\n",
    "    \n",
    "    def future_mask(self, seq_len):\n",
    "        '''mask out tokens at future positions'''\n",
    "        mask = (torch.triu(torch.ones(seq_len, seq_len, requires_grad=False), diagonal=1)!=0).to(DEVICE)\n",
    "        return mask.view(1, 1, seq_len, seq_len)\n",
    "\n",
    "    def forward(self, memory, src_mask, trg, trg_pad_mask):\n",
    "        seq_len = trg.size(1)\n",
    "        trg_mask = torch.logical_or(trg_pad_mask, self.future_mask(seq_len))\n",
    "        x = self.tok_embed(trg) + self.pos_embed[:, :trg.size(1), :]\n",
    "        x = self.dropout(x)\n",
    "        for layer in self.decoder_blocks:\n",
    "            x = layer(memory, src_mask, x, trg_mask)\n",
    "        x = self.norm(x)\n",
    "        logits = self.linear(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    ''' EncoderBlock: self-attention -> position-wise feed-forward (fully connected) layer'''\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.atten1 = MultiHeadedAttention(config.h, config.d_embed)\n",
    "        self.atten2 = MultiHeadedAttention(config.h, config.d_embed)\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(config.d_embed, config.d_ff),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(config.dropout),\n",
    "            nn.Linear(config.d_ff, config.d_embed)\n",
    "        )\n",
    "        self.residuals = nn.ModuleList([ResidualConnection(config.d_embed, config.dropout) \n",
    "                                       for i in range(3)])\n",
    "\n",
    "    def forward(self, memory, src_mask, decoder_layer_input, trg_mask):\n",
    "        x = memory\n",
    "        y = decoder_layer_input\n",
    "        y = self.residuals[0](y, lambda y: self.atten1(y, y, y, mask=trg_mask))\n",
    "        # keys and values are from the encoder output\n",
    "        y = self.residuals[1](y, lambda y: self.atten2(y, x, x, mask=src_mask))\n",
    "        return self.residuals[2](y, self.feed_forward)\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, src, src_mask, trg, trg_pad_mask):\n",
    "        return self.decoder(self.encoder(src, src_mask), src_mask, trg, trg_pad_mask)\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T11:15:37.078042Z",
     "iopub.status.busy": "2024-11-17T11:15:37.077161Z",
     "iopub.status.idle": "2024-11-17T11:15:38.263988Z",
     "shell.execute_reply": "2024-11-17T11:15:38.263188Z",
     "shell.execute_reply.started": "2024-11-17T11:15:37.078002Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch.nn.functional as F\n",
    "\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    encoder_vocab_size: int\n",
    "    decoder_vocab_size: int\n",
    "    d_embed: int\n",
    "    # d_ff is the dimension of the fully-connected  feed-forward layer\n",
    "    d_ff: int\n",
    "    # h is the number of attention head\n",
    "    h: int\n",
    "    N_encoder: int\n",
    "    N_decoder: int\n",
    "    max_seq_len: int\n",
    "    dropout: float\n",
    "\n",
    "def make_model(config):\n",
    "    model = Transformer(Encoder(config), Decoder(config)).to(DEVICE)\n",
    "\n",
    "    # initialize model parameters\n",
    "    # it seems that this initialization is very important!\n",
    "    for p in model.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T11:15:40.035555Z",
     "iopub.status.busy": "2024-11-17T11:15:40.034950Z",
     "iopub.status.idle": "2024-11-17T11:15:40.041643Z",
     "shell.execute_reply": "2024-11-17T11:15:40.040544Z",
     "shell.execute_reply.started": "2024-11-17T11:15:40.035516Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Modified training configuration\n",
    "config = ModelConfig(\n",
    "    encoder_vocab_size=vocab_sizes[SRC],\n",
    "    decoder_vocab_size=vocab_sizes[TRG],\n",
    "    d_embed=256,  \n",
    "    d_ff=512,\n",
    "    h=8,\n",
    "    N_encoder=3,\n",
    "    N_decoder=3,\n",
    "    max_seq_len=max_seq_len,\n",
    "    dropout=0.2  # Increased dropout for better regularization with small dataset\n",
    ")\n",
    "\n",
    "# Modified training parameters\n",
    "warmup_steps = 4 * len(Dataloaders().train_loader)  # Adjusted for smaller dataset\n",
    "early_stop_count = 3  # Increased patience for smaller dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T11:15:43.443601Z",
     "iopub.status.busy": "2024-11-17T11:15:43.443210Z",
     "iopub.status.idle": "2024-11-17T11:15:43.478032Z",
     "shell.execute_reply": "2024-11-17T11:15:43.477024Z",
     "shell.execute_reply.started": "2024-11-17T11:15:43.443566Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def make_batch_input(x, y):\n",
    "        src = x.to(DEVICE)\n",
    "        trg_in = y[:, :-1].to(DEVICE)\n",
    "        trg_out = y[:, 1:].contiguous().view(-1).to(DEVICE)\n",
    "        src_pad_mask = (src == PAD).view(src.size(0), 1, 1, src.size(-1))\n",
    "        trg_pad_mask = (trg_in == PAD).view(trg_in.size(0), 1, 1, trg_in.size(-1))\n",
    "        return src, trg_in, trg_out, src_pad_mask, trg_pad_mask\n",
    "     \n",
    "\n",
    "from numpy.lib.utils import lookfor\n",
    "def train_epoch(model, dataloaders):\n",
    "    model.train()\n",
    "    grad_norm_clip = 1.0\n",
    "    losses, acc, count = [], 0, 0\n",
    "    num_batches = len(dataloaders.train_loader)\n",
    "    pbar = tqdm(enumerate(dataloaders.train_loader), total=num_batches)\n",
    "    for idx, (x, y)  in  pbar:\n",
    "        optimizer.zero_grad()\n",
    "        src, trg_in, trg_out, src_pad_mask, trg_pad_mask = make_batch_input(x,y)\n",
    "        pred = model(src, src_pad_mask, trg_in, trg_pad_mask).to(DEVICE)\n",
    "        pred = pred.view(-1, pred.size(-1))\n",
    "        loss = loss_fn(pred, trg_out).to(DEVICE)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), grad_norm_clip)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        losses.append(loss.item())\n",
    "        # report progress\n",
    "        if idx>0 and idx%50 == 0:\n",
    "            pbar.set_description(f'train loss={loss.item():.3f}, lr={scheduler.get_last_lr()[0]:.5f}')\n",
    "    return np.mean(losses)\n",
    "\n",
    "\n",
    "def train(model, dataloaders, epochs):\n",
    "    global early_stop_count\n",
    "    best_valid_loss = float('inf')\n",
    "    train_size = len(dataloaders.train_loader) * batch_size\n",
    "    \n",
    "    try:\n",
    "        for ep in range(epochs):\n",
    "            train_loss = train_epoch(model, dataloaders)\n",
    "            valid_loss = validate(model, dataloaders.valid_loader)\n",
    "            \n",
    "            print(f'Epoch {ep + 1}/{epochs}:')\n",
    "            print(f'Train Loss: {train_loss:.5f}')\n",
    "            print(f'Valid Loss: {valid_loss:.5f}')\n",
    "            \n",
    "            # Save model checkpoint\n",
    "            if valid_loss < best_valid_loss:\n",
    "                best_valid_loss = valid_loss\n",
    "                torch.save({\n",
    "                    'epoch': ep,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'valid_loss': valid_loss,\n",
    "                }, 'best_model_checkpoint.pt')\n",
    "            else:\n",
    "                if scheduler.last_epoch > 2 * warmup_steps:\n",
    "                    early_stop_count -= 1\n",
    "                    print(f'Early stopping counter: {early_stop_count}')\n",
    "                    if early_stop_count <= 0:\n",
    "                        print('Early stopping triggered')\n",
    "                        break\n",
    "            \n",
    "            print('-' * 50)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during training: {str(e)}\")\n",
    "        return None, None\n",
    "    \n",
    "    return train_loss, valid_loss\n",
    "      \n",
    "               \n",
    "def validate(model, dataloder):\n",
    "    'compute the validation loss'\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for i, (x, y) in enumerate(dataloder):\n",
    "            src, trg_in, trg_out, src_pad_mask, trg_pad_mask = make_batch_input(x,y)\n",
    "            pred = model(src, src_pad_mask, trg_in, trg_pad_mask).to(DEVICE)\n",
    "            pred = pred.view(-1, pred.size(-1))\n",
    "            losses.append(loss_fn(pred, trg_out).item())\n",
    "    return np.mean(losses)\n",
    "     \n",
    "\n",
    "def translate(model, x):\n",
    "    'translate source sentences into the target language, without looking at the answer'\n",
    "    with torch.no_grad():\n",
    "        try:\n",
    "            dB = x.size(0)\n",
    "            y = torch.tensor([[BOS] * dB]).view(dB, 1).to(DEVICE)\n",
    "            x_pad_mask = (x == PAD).view(x.size(0), 1, 1, x.size(-1)).to(DEVICE)\n",
    "            memory = model.encoder(x, x_pad_mask)\n",
    "            \n",
    "            for i in range(max_seq_len):\n",
    "                y_pad_mask = (y == PAD).view(y.size(0), 1, 1, y.size(-1)).to(DEVICE)\n",
    "                logits = model.decoder(memory, x_pad_mask, y, y_pad_mask)\n",
    "                last_output = logits.argmax(-1)[:, -1]\n",
    "                last_output = last_output.view(dB, 1)\n",
    "                y = torch.cat((y, last_output), 1).to(DEVICE)\n",
    "                \n",
    "                # Stop if all sequences have generated EOS token\n",
    "                if ((y == EOS).sum(dim=1) > 0).all():\n",
    "                    break\n",
    "            \n",
    "            return y\n",
    "        except Exception as e:\n",
    "            print(f\"Error in translation: {str(e)}\")\n",
    "            return torch.tensor([[BOS, EOS]]).to(DEVICE)\n",
    "     \n",
    "\n",
    "def remove_pad(sent):\n",
    "    '''truncate the sentence if BOS is in it,\n",
    "     otherwise simply remove the padding tokens at the end'''\n",
    "    if sent.count(EOS)>0:\n",
    "      sent = sent[0:sent.index(EOS)+1]\n",
    "    while sent and sent[-1] == PAD:\n",
    "            sent = sent[:-1]\n",
    "    return sent\n",
    "\n",
    "def decode_sentence(detokenizer, sentence_ids):\n",
    "    'convert a tokenized sentence (a list of numbers) to a literal string'\n",
    "    if not isinstance(sentence_ids, list):\n",
    "        sentence_ids = sentence_ids.tolist()\n",
    "    sentence_ids = remove_pad(sentence_ids)\n",
    "    try:\n",
    "        return detokenizer(sentence_ids).replace(\"\", \"\").replace(\"\", \"\").strip().replace(\" .\", \".\")\n",
    "    except:\n",
    "        return \"\"  # Return empty string if decoding fails\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, num_batch=None):\n",
    "    'evaluate the model, and compute the BLEU score'\n",
    "    model.eval()\n",
    "    refs, cans = [], []\n",
    "    example_count = 0\n",
    "    max_examples = 3  # Number of examples to print\n",
    "    printed_examples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, (x, y) in enumerate(dataloader):\n",
    "            if num_batch and idx >= num_batch:\n",
    "                break\n",
    "                \n",
    "            src, trg_in, trg_out, src_pad_mask, trg_pad_mask = make_batch_input(x, y)\n",
    "            translation = translate(model, src)\n",
    "            trg_out = trg_out.view(x.size(0), -1)\n",
    "            \n",
    "            batch_size = len(src)\n",
    "            for i in range(batch_size):\n",
    "                refs.append(decode_sentence(detokenizers[TRG], trg_out[i]))\n",
    "                cans.append(decode_sentence(detokenizers[TRG], translation[i]))\n",
    "                \n",
    "                # Print examples only if we haven't printed enough yet\n",
    "                if printed_examples < max_examples:\n",
    "                    try:\n",
    "                        print(f'Example {printed_examples + 1}:')\n",
    "                        print(f'src:  {decode_sentence(detokenizers[SRC], src[i])}')\n",
    "                        print(f'trg:  {decode_sentence(detokenizers[TRG], trg_out[i])}')\n",
    "                        print(f'pred: {decode_sentence(detokenizers[TRG], translation[i])}')\n",
    "                        print('-' * 50)\n",
    "                        printed_examples += 1\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error printing example: {str(e)}\")\n",
    "                        continue\n",
    "            \n",
    "            example_count += batch_size\n",
    "    \n",
    "    # Compute BLEU score\n",
    "    try:\n",
    "        bleu_score = sacrebleu.corpus_bleu(cans, [refs]).score\n",
    "    except Exception as e:\n",
    "        print(f\"Error computing BLEU score: {str(e)}\")\n",
    "        bleu_score = 0.0\n",
    "    \n",
    "    print(f\"Evaluated {example_count} examples\")\n",
    "    return bleu_score\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T11:15:44.347409Z",
     "iopub.status.busy": "2024-11-17T11:15:44.346700Z",
     "iopub.status.idle": "2024-11-17T11:17:10.755242Z",
     "shell.execute_reply": "2024-11-17T11:17:10.754144Z",
     "shell.execute_reply.started": "2024-11-17T11:15:44.347368Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 6,568,888 parameters\n",
      "Training set size: 7,424 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss=4.846, lr=0.00034: 100%|██████████| 232/232 [00:07<00:00, 31.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15:\n",
      "Train Loss: 6.01667\n",
      "Valid Loss: 4.71377\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss=4.042, lr=0.00074: 100%|██████████| 232/232 [00:06<00:00, 33.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/15:\n",
      "Train Loss: 4.25581\n",
      "Valid Loss: 4.02560\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss=3.571, lr=0.00113: 100%|██████████| 232/232 [00:06<00:00, 34.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/15:\n",
      "Train Loss: 3.69276\n",
      "Valid Loss: 3.72622\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss=3.110, lr=0.00104: 100%|██████████| 232/232 [00:07<00:00, 32.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/15:\n",
      "Train Loss: 3.30319\n",
      "Valid Loss: 3.51672\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss=2.892, lr=0.00093: 100%|██████████| 232/232 [00:06<00:00, 33.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/15:\n",
      "Train Loss: 2.98384\n",
      "Valid Loss: 3.35408\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss=2.841, lr=0.00085: 100%|██████████| 232/232 [00:06<00:00, 33.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/15:\n",
      "Train Loss: 2.74480\n",
      "Valid Loss: 3.26792\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss=2.663, lr=0.00078: 100%|██████████| 232/232 [00:06<00:00, 34.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/15:\n",
      "Train Loss: 2.56021\n",
      "Valid Loss: 3.21527\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss=2.355, lr=0.00073: 100%|██████████| 232/232 [00:06<00:00, 34.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/15:\n",
      "Train Loss: 2.40832\n",
      "Valid Loss: 3.21977\n",
      "Early stopping counter: 1\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss=2.248, lr=0.00069: 100%|██████████| 232/232 [00:06<00:00, 33.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/15:\n",
      "Train Loss: 2.27528\n",
      "Valid Loss: 3.17913\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss=2.290, lr=0.00065: 100%|██████████| 232/232 [00:06<00:00, 34.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/15:\n",
      "Train Loss: 2.16870\n",
      "Valid Loss: 3.21625\n",
      "Early stopping counter: 0\n",
      "Early stopping triggered\n",
      "train set examples:\n",
      "Example 1:\n",
      "src:  But and if that servant say in his heart , My lord delayeth his coming ; and shall begin to beat the menservants and maidens , and to eat and drink , and to be drunken.\n",
      "trg:  لیکن اگر وہ نوکر اپنے دل میں یہ کہہ کر کہ میرے مالک کے آنے میں دیر ہے غلاموں اور لونڈیوں کو مارنا اور کھا پی کر متوالا ہونا شروع کرے ۔\n",
      "pred: لیکن اگر وہ اپنی مرضی کے مالک کی مانند ہے تو میری مانند ہے اور اس کے پاس آکر کہا کہ یہاں گوشت اور قتل کریں گوشت اور قتل کریں گوشت کھاو ۔\n",
      "--------------------------------------------------\n",
      "Example 2:\n",
      "src:  Notwithstanding the Lord stood with me , and strengthened me ; that by me the preaching might be fully known , and that all the Gentiles might hear : and I was delivered out of the mouth of the lion.\n",
      "trg:  مگر خداوند میرا مددگار تھا اور اس نے مجھے طاقت بخشی تاکہ میری معرفت پیغام کی پوری منادی ہو جائے اور سب غیرقومویں سن لیں ۔ اور میں شیر کے منہ سے چھڑایا گیا ۔\n",
      "pred: مگر خداوند نے مجھ سے کہا میری خوشخبری کے ساتھ مجھ پر قائم رہیں تاکہ مجھ پر ایمان لائیں اور میں نے مجھ سے میں سب کو معلوم کیا کہ سب نے سب قوموں کو میں نے سب کی میں میں میں نے سب کچھ میں نے سب کو خوشخبری کی میں ڈال دیا تھا ۔\n",
      "--------------------------------------------------\n",
      "Example 3:\n",
      "src:  That the aged men be sober , grave , temperate , sound in faith , in charity , in patience.\n",
      "trg:  یعنی یہ کہ بوڑھے مرد پرہیزگار ، سنجیدہ اور متقی ہوں اور ان کا ایمان اور محبت اور صبر صحیح ہو ۔\n",
      "pred: اور آدمیوں کے لئے بلائے ہوئے بلکہ میں بھی ۔ پرہیزگاری اور صبر ہو ۔\n",
      "--------------------------------------------------\n",
      "Evaluated 640 examples\n",
      "validation set examples:\n",
      "Example 1:\n",
      "src:  And round about the throne were four and twenty seats : and upon the seats I saw four and twenty elders sitting , clothed in white raiment ; and they had on their heads crowns of gold.\n",
      "trg:  اور اس تخت کے گرد چوبیس تخت ہیں اور ان تختوں پر چوبیس بزرگ سفید پوشاک پہنے ہوئے بیٹھے ہیں اور ان کے سروں پر سونے کے تاج ہیں ۔\n",
      "pred: اور زمانہ کے لوگوں کے تختب سے باندھا اور ان کے تختوں پر بیٹھ کر ان کے کپڑوں پر بیٹھ کر ان کے کپڑوں کے کپڑوں پر بیٹھ کر کھیتوں میں بیٹھ کر کھیت کوڑےایا ۔\n",
      "--------------------------------------------------\n",
      "Example 2:\n",
      "src:  These are murmurers , complainers , walking after their own lusts ; and their mouth speaketh great swelling words , having men ' s persons in admiration because of advantage.\n",
      "trg:  یہ بڑبڑانے والے اور شکایت کرنے والے ہیں اور اپنی خواہشوں کے موافق چلتے ہیں اور اپنے منہ سے بڑے بول بولتے ہیں اور نفع کے لئے لوگوں کی روداری کرتے ہیں ۔\n",
      "pred: یہ باتیں کہیں کہیں اور اپنی خواہشوں کے لئے نماز پر چلتی ہیں اور ان کی خواہشوں کے لئے نمای کی خواہشوں کے لئے نماز پر لعن طعن کرتا ہے ۔\n",
      "--------------------------------------------------\n",
      "Example 3:\n",
      "src:  Having many things to write unto you , I would not write with paper and ink : but I trust to come unto you , and speak face to face , that our joy may be full.\n",
      "trg:  مجھے بہت سی باتیں تم کو لکھنا ہے مگر کاغذ اور سیاہی سے لکھنا نہیں چاہتا بلکہ تمہارے پاس آنے اور روبرو بات چیت کرنے کی امید رکھتا ہوں تاکہ تمہاری خوشی کامل ہو ۔\n",
      "pred: اور بہت سے لوگ تمہیں لکھتا ہوں کہ میں جاکر ایسی باتیں نہیں بلکہ صاف کرنے والوں کو بھی صاف کروں اور تمہیں یاد کرنے والا خوشخبری دوں گا ۔\n",
      "--------------------------------------------------\n",
      "Evaluated 300 examples\n",
      "test set examples:\n",
      "Example 1:\n",
      "src:  He which testifieth these things saith , Surely I come quickly. Amen. Even so , come , Lord Jesus.\n",
      "trg:  جو ان باتوں کی گواہی دیتا ہے اور یہ کہتا ہے کہ بیشک میں جلد آنے والا ہوں ۔ آمین ۔ اے خداوند یسوع آ ۔\n",
      "pred: جو باتیں کہتی ہے ان سے کہا میں نے یہ باتیں اب تک اب تک اب تک اب تک ابن آدم کو سلام کہتی ہے ۔\n",
      "--------------------------------------------------\n",
      "Example 2:\n",
      "src:  And I saw thrones , and they sat upon them , and judgment was given unto them : and I saw the souls of them that were beheaded for the witness of Jesus , and for the word of God , and which had not worshipped the beast , neither his image , neither had received his mark upon their foreheads , or in\n",
      "trg:  پھر میں نے تخت دیکھے اور لوگ ان پر بیٹھ گئے اور عدالت ان کے سپرد کی گئی اور ان کی روحوں کو بھی دیکھا جن کے سر یسوع کی گواہی دینے اور خدا کے کلام کے سبب سے کاٹے گئے تھے اور جنہوں نے نہ اس حیوان کی پرستش کی تھی نہ اس کے بت کی اور نہ اس کی چھاپ اپنے ماتھے اور ہاتھوں پر لی تھی ۔ وہ زندہ ہو کر ہزار برس تک مسیح کے ساتھ\n",
      "pred: اور میں نے دیکھ کر ان کو آگیا اور ان کے تخت عدالت میں بیٹھ کر ان کے لئے میں بیٹھا ہوں اور ان کے لئے میں نے ان کی طرف رجوع لائیں اور ان کے لئے خدا کی طرف سے نہ کیا اور اس کا کلام کیا تھا ۔\n",
      "--------------------------------------------------\n",
      "Example 3:\n",
      "src:  And the devil that deceived them was cast into the lake of fire and brimstone , where the beast and the false prophet are , and shall be tormented day and night for ever and ever.\n",
      "trg:  اور ان کا گمراہ کرنے والا ابلیس آگ اور گندھک کی اس جھیل میں ڈالا جائے گا جہاں وہ حیوان اور جھوٹا نبی بھی ہوگا اور وہ رات دن ابدالآباد عذاب میں رہیں گے ۔\n",
      "pred: اور ابلیس نے ان کو قتل کیا اور سانپوں کو رد کیا اور تین دن تک کہ اٹھ کریں گرفتار ہونگی اور وہاں سے آگ میں ڈالیں گرفتار رہے گا ۔\n",
      "--------------------------------------------------\n",
      "Evaluated 257 examples\n",
      "train_loss: 2.1687, valid_loss: 3.2163, test_loss: 3.7773\n",
      "test_bleu: 3.8234, valid_bleu: 4.9718 train_bleu: 10.9246\n"
     ]
    }
   ],
   "source": [
    "data_loaders = Dataloaders()\n",
    "train_size = len(data_loaders.train_loader)*batch_size\n",
    "model = make_model(config)\n",
    "model_size = sum([p.numel() for p in model.parameters()])\n",
    "print(f'Model size: {model_size:,} parameters')\n",
    "print(f'Training set size: {train_size:,} samples')\n",
    "warmup_steps = 3*len(data_loaders.train_loader)\n",
    "lr_fn = lambda step: config.d_embed**(-0.5) * min([(step+1)**(-0.5), (step+1)*warmup_steps**(-1.5)])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.5, betas=(0.9, 0.98), eps=1e-9)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_fn)\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=PAD)\n",
    "early_stop_count = 2\n",
    "train_loss, valid_loss = train(model, data_loaders, epochs=15)\n",
    "test_loss  = validate(model, data_loaders.test_loader)\n",
    "\n",
    "print(\"train set examples:\")\n",
    "train_bleu = evaluate(model, data_loaders.train_loader, 20)\n",
    "print(\"validation set examples:\")\n",
    "valid_bleu = evaluate(model, data_loaders.valid_loader)\n",
    "print(\"test set examples:\")\n",
    "test_bleu  = evaluate(model, data_loaders.test_loader)\n",
    "print(f'train_loss: {train_loss:.4f}, valid_loss: {valid_loss:.4f}, test_loss: {test_loss:.4f}')\n",
    "print(f'test_bleu: {test_bleu:.4f}, valid_bleu: {valid_bleu:.4f} train_bleu: {train_bleu:.4f}')\n",
    "torch.save(model.state_dict(), 'final_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T11:20:59.997301Z",
     "iopub.status.busy": "2024-11-17T11:20:59.996439Z",
     "iopub.status.idle": "2024-11-17T11:21:01.092345Z",
     "shell.execute_reply": "2024-11-17T11:21:01.091388Z",
     "shell.execute_reply.started": "2024-11-17T11:20:59.997253Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output: جو باتیں ان سے کہا میں نے یہ باتیں اب تک آکر یسوع کے پاس آکر کہا اے خداوند ! میں بھی اب تک قائم رہو ۔\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/seaborn/utils.py:80: UserWarning: Glyph 1746 (\\N{ARABIC LETTER YEH BARREE}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/utils.py:80: UserWarning: Matplotlib currently does not support Arabic natively.\n",
      "  fig.canvas.draw()\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/utils.py:80: UserWarning: Glyph 1729 (\\N{ARABIC LETTER HEH GOAL}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/utils.py:80: UserWarning: Glyph 1748 (\\N{ARABIC FULL STOP}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/opt/conda/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 1746 (\\N{ARABIC LETTER YEH BARREE}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/opt/conda/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Matplotlib currently does not support Arabic natively.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/opt/conda/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 1729 (\\N{ARABIC LETTER HEH GOAL}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/opt/conda/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 1748 (\\N{ARABIC FULL STOP}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def demo_attention(model, sentence):\n",
    "    \"\"\"\n",
    "    Demonstrate attention visualization for a given sentence\n",
    "    \"\"\"\n",
    "    translation, attention_weights = translate_with_attention(model, sentence, tokenizers)\n",
    "    \n",
    "    # Get tokens\n",
    "    src_tokens = [en_sp.decode_pieces([en_sp.id_to_piece(id)]) for id in tokenizers[\"en\"](sentence)]\n",
    "    trg_tokens = [ur_sp.decode_pieces([ur_sp.id_to_piece(id)]) for id in tokenizers[\"ur\"](translation)]\n",
    "\n",
    "    print(f\"\\nOutput: {translation}\")\n",
    "    # Visualize attention\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(attention_weights[:len(trg_tokens), :len(src_tokens)],\n",
    "                xticklabels=src_tokens,\n",
    "                yticklabels=trg_tokens,\n",
    "                cmap='viridis',\n",
    "                square=True)\n",
    "    plt.xlabel('English Words')\n",
    "    plt.ylabel('Urdu Words')\n",
    "    plt.title(f'Attention Weights: English → Urdu Translation\\nInput: {sentence}')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    return plt\n",
    "\n",
    "sentence = \"He which testifieth these things saith , Surely I come quickly. Amen. Even so , come , Lord Jesus.\"\n",
    "demo_attention(model, sentence)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T11:21:29.137347Z",
     "iopub.status.busy": "2024-11-17T11:21:29.136406Z",
     "iopub.status.idle": "2024-11-17T11:21:29.143102Z",
     "shell.execute_reply": "2024-11-17T11:21:29.142213Z",
     "shell.execute_reply.started": "2024-11-17T11:21:29.137291Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def translate_this_sentence(text: str):\n",
    "    'translate the Urdu sentence into English'\n",
    "    input = torch.tensor([[BOS] + tokenizers[SRC](text) + [EOS]]).to(DEVICE)\n",
    "    output = translate(model, input)\n",
    "    return decode_sentence(detokenizers[TRG], output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T11:21:30.886656Z",
     "iopub.status.busy": "2024-11-17T11:21:30.886306Z",
     "iopub.status.idle": "2024-11-17T11:27:42.158484Z",
     "shell.execute_reply": "2024-11-17T11:27:42.157404Z",
     "shell.execute_reply.started": "2024-11-17T11:21:30.886623Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 5.619, Valid Loss = 5.616\n",
      "Epoch 2: Train Loss = 5.236, Valid Loss = 5.703\n",
      "Epoch 3: Train Loss = 5.057, Valid Loss = 5.653\n",
      "Epoch 4: Train Loss = 4.953, Valid Loss = 5.751\n",
      "Epoch 5: Train Loss = 4.875, Valid Loss = 5.658\n",
      "Epoch 6: Train Loss = 4.812, Valid Loss = 5.682\n",
      "Epoch 7: Train Loss = 4.718, Valid Loss = 5.662\n",
      "Epoch 8: Train Loss = 4.655, Valid Loss = 5.661\n",
      "Epoch 9: Train Loss = 4.593, Valid Loss = 5.660\n",
      "Epoch 10: Train Loss = 4.553, Valid Loss = 5.686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating: 100%|██████████| 257/257 [00:05<00:00, 47.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 12.17\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define LSTM Encoder\n",
    "class LSTMEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hidden_dim, n_layers, dropout):\n",
    "        super(LSTMEncoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.lstm = nn.LSTM(emb_dim, hidden_dim, n_layers, dropout=dropout, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        outputs, (hidden, cell) = self.lstm(embedded)\n",
    "        return hidden, cell\n",
    "\n",
    "# Define LSTM Decoder\n",
    "class LSTMDecoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hidden_dim, n_layers, dropout):\n",
    "        super(LSTMDecoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.lstm = nn.LSTM(emb_dim, hidden_dim, n_layers, dropout=dropout, batch_first=True)\n",
    "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, trg, hidden, cell):\n",
    "        trg = trg.unsqueeze(1)  # Add batch dimension\n",
    "        embedded = self.dropout(self.embedding(trg))\n",
    "        output, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
    "        prediction = self.fc_out(output.squeeze(1))\n",
    "        return prediction, hidden, cell\n",
    "\n",
    "# Define Seq2Seq Model\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        trg_len = trg.size(1)\n",
    "        batch_size = trg.size(0)\n",
    "        trg_vocab_size = self.decoder.fc_out.out_features\n",
    "\n",
    "        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(self.device)\n",
    "        hidden, cell = self.encoder(src)\n",
    "        \n",
    "        trg_token = trg[:, 0]\n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden, cell = self.decoder(trg_token, hidden, cell)\n",
    "            outputs[:, t, :] = output\n",
    "            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1)\n",
    "            trg_token = trg[:, t] if teacher_force else top1\n",
    "        return outputs\n",
    "\n",
    "# Initialize the Model\n",
    "INPUT_DIM = vocab_sizes[\"en\"]\n",
    "OUTPUT_DIM = vocab_sizes[\"ur\"]\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "HIDDEN_DIM = 512\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "encoder = LSTMEncoder(INPUT_DIM, ENC_EMB_DIM, HIDDEN_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "decoder = LSTMDecoder(OUTPUT_DIM, DEC_EMB_DIM, HIDDEN_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "model = Seq2Seq(encoder, decoder, DEVICE).to(DEVICE)\n",
    "\n",
    "# Loss Function and Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=PAD)\n",
    "\n",
    "# Training and Evaluation\n",
    "def train_epoch_lstm(model, dataloader, optimizer, loss_fn):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for src, trg in dataloader:\n",
    "        src, trg = src.to(DEVICE), trg.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg)\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[:, 1:].reshape(-1, output_dim)\n",
    "        trg = trg[:, 1:].reshape(-1)\n",
    "        loss = loss_fn(output, trg)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(dataloader)\n",
    "\n",
    "def evaluate_lstm(model, dataloader, loss_fn):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for src, trg in dataloader:\n",
    "            src, trg = src.to(DEVICE), trg.to(DEVICE)\n",
    "            output = model(src, trg, teacher_forcing_ratio=0)  # No teacher forcing during evaluation\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output[:, 1:].reshape(-1, output_dim)\n",
    "            trg = trg[:, 1:].reshape(-1)\n",
    "            loss = loss_fn(output, trg)\n",
    "            epoch_loss += loss.item()\n",
    "    return epoch_loss / len(dataloader)\n",
    "\n",
    "from sacrebleu import corpus_bleu\n",
    "# Function to generate translations\n",
    "def translate_sentence(model, src_sentence, src_tokenizer, trg_detokenizer, max_len=100):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        src_tensor = torch.tensor([BOS] + src_tokenizer(src_sentence)[:max_len-2] + [EOS]).unsqueeze(0).to(DEVICE)\n",
    "        hidden, cell = model.encoder(src_tensor)\n",
    "\n",
    "        trg_indexes = [BOS]\n",
    "        for _ in range(max_len):\n",
    "            trg_tensor = torch.tensor([trg_indexes[-1]]).to(DEVICE)\n",
    "            output, hidden, cell = model.decoder(trg_tensor, hidden, cell)\n",
    "            pred_token = output.argmax(1).item()\n",
    "            trg_indexes.append(pred_token)\n",
    "            if pred_token == EOS:\n",
    "                break\n",
    "\n",
    "        trg_tokens = trg_indexes[1:]  # Remove BOS token\n",
    "        return trg_detokenizer(trg_tokens)\n",
    "\n",
    "# Evaluate BLEU score\n",
    "def calculate_bleu(model, test_dataset, detokenizers, max_len=100):\n",
    "    references = []\n",
    "    hypotheses = []\n",
    "    for src_text, trg_text in tqdm(test_dataset, desc=\"Translating\"):\n",
    "        # Convert tensor back to text for ground truth\n",
    "        trg_text_actual = detokenizers[TRG](trg_text.tolist()[1:-1])  # Exclude BOS and EOS\n",
    "        references.append([trg_text_actual])  # SacreBLEU expects list of references for each sentence\n",
    "        \n",
    "        # Translate the source sentence\n",
    "        src_text_original = detokenizers[SRC](src_text.tolist()[1:-1])  # Exclude BOS and EOS\n",
    "        hypothesis = translate_sentence(model, src_text_original, tokenizers[SRC], detokenizers[TRG], max_len)\n",
    "        hypotheses.append(hypothesis)\n",
    "    \n",
    "    # Calculate BLEU score\n",
    "    bleu = corpus_bleu(hypotheses, references)\n",
    "    return bleu.score\n",
    "\n",
    "# Training Loop\n",
    "EPOCHS = 10\n",
    "dataloaders = Dataloaders()  # Using the same dataloader structure\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss = train_epoch_lstm(model, dataloaders.train_loader, optimizer, loss_fn)\n",
    "    valid_loss = evaluate_lstm(model, dataloaders.valid_loader, loss_fn)\n",
    "    print(f\"Epoch {epoch+1}: Train Loss = {train_loss:.3f}, Valid Loss = {valid_loss:.3f}\")\n",
    "\n",
    "\n",
    "# Calculate BLEU score on the test set\n",
    "bleu_score = calculate_bleu(model, test_tokenized, detokenizers, max_seq_len)\n",
    "print(f\"BLEU Score: {bleu_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T11:27:42.160543Z",
     "iopub.status.busy": "2024-11-17T11:27:42.160195Z",
     "iopub.status.idle": "2024-11-17T11:27:42.234281Z",
     "shell.execute_reply": "2024-11-17T11:27:42.233250Z",
     "shell.execute_reply.started": "2024-11-17T11:27:42.160509Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1:\n",
      "Original English: For they have shed the blood of saints and prophets , and thou hast given them blood to drink ; for they are worthy .                                       \n",
      "Original Urdu:    کیونکہ انہوں نے مقدسوں اور نبیوں کا خون بہایا تھا اور تو نے انہیں خون پلایا ۔ وہ اسی لائق ہیں ۔ےےےےےےےےےےےےےےےےےےےےےےےےےےےےےےےےےےےےےےے\n",
      "Predicted Urdu:   کیونکہ وہ کے سبب سے میں سےی کےیں اوری اوریں اوریں اوریں اوریں ۔ ۔ ۔\n",
      "--------------------------------------------------\n",
      "Example 2:\n",
      "Original English: For God hath put in their hearts to fulfil his will , and to agree , and give their kingdom unto the beast , until the words of God shall be fulfilled .                               \n",
      "Original Urdu:    کیونکہ خدا ان کے دلوں میں یہ ڈالے گا کہ وہ اس کی رای پر چلیں اور جب تک کہ خدا کی باتیں پوری نہ ہو لیں وہ متفق الرای ہوکر اپنی بادشاہی اس حیوان کو دے دیں ۔ےےےےےےےےےےے\n",
      "Predicted Urdu:   کیونکہ وہ کے سبب سے میں سےی کےیں اوریں اوریں اوریں اوریں اوریں اوریں اوریں اوریں اوریں اوریں اوریں ۔ ۔\n",
      "--------------------------------------------------\n",
      "Example 3:\n",
      "Original English: For true and righteous are his judgments : for he hath judged the great whore , which did corrupt the earth with her fornication , and hath avenged the blood of his servants at her hand .                     \n",
      "Original Urdu:    کیونکہ اس کے فیصلے راست اور درست ہیں اس لئے کہ اس نے اس بڑی کسبی کا انصاف کیا جس نے اپنی حرامکاری سے دنیا کو خراب کیا تھا اور اس نے اپنے بندوں کے خون کا بدلہ لیا ۔ےےےےےےےےےےےےےےےےےےےے\n",
      "Predicted Urdu:   کیونکہ وہ کے سبب سے جو اس کے کے کے کے کے ساتھئے اور اور اور اور اور اور اوری کےیں اوریں اوریں اوریں اوریں اوریں اوریں ۔ ۔ ۔\n",
      "--------------------------------------------------\n",
      "Example 4:\n",
      "Original English: And the ten horns which thou sawest are ten kings , which have received no kingdom as yet ; but receive power as kings one hour with the beast .                                \n",
      "Original Urdu:    اور وہ دس سینگ جو تو نے دیکھے دس بادشاہ ہیں ۔ ابھی تک انہوں نے بادشاہی نہیں پائی مگر اس حیوان کے ساتھ گھڑی بھر کے واسطے بادشاہوں کا سا اختیار پائیں گے ۔ےےےےےےےےےےےےےےےےےےےےےےے\n",
      "Predicted Urdu:   اور اگر کوئی اپنی آپ کو میں سےا اور اور اور اور اور اور اور اوریں اوریں اوریں اوریں اوریں ۔ ۔\n",
      "--------------------------------------------------\n",
      "Example 5:\n",
      "Original English: Let us be glad and rejoice , and give honour to him : for the marriage of the Lamb is come , and his wife hath made herself ready .                                \n",
      "Original Urdu:    آؤ ۔ ہم خوشی کریں اور نہایت شادمان ہوں اور اس کی تمجید کریں اس لئے کہ برہ کی شادی آ پہنچی اور اس کی بیوی نے اپنے آپ کو تیار کر لیا ۔ےےےےےےےےےےےےےےےےےےےےےےےےے\n",
      "Predicted Urdu:   پس ہم نے اپنی آپ کو میں سےی اور اور اور اور اور اور اور اور اور اوری اوریں اوری کےیں ۔ ۔\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def display_predictions(model, dataloader, detokenizers, num_examples=5):\n",
    "    \"\"\"\n",
    "    Display predictions for a few examples from the test set.\n",
    "    Args:\n",
    "        model: Trained Seq2Seq model.\n",
    "        dataloader: DataLoader for the test set.\n",
    "        detokenizers: Dictionary containing detokenizers for both languages.\n",
    "        num_examples: Number of examples to display.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    examples = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for src, trg in dataloader:\n",
    "            src = src.to(DEVICE)\n",
    "            trg = trg.to(DEVICE)\n",
    "            \n",
    "            batch_size = src.size(0)\n",
    "            hidden, cell = model.encoder(src)\n",
    "            \n",
    "            trg_token = torch.tensor([BOS] * batch_size).to(DEVICE)\n",
    "            translation_batch = []\n",
    "            \n",
    "            for _ in range(max_seq_len):\n",
    "                output, hidden, cell = model.decoder(trg_token, hidden, cell)\n",
    "                trg_token = output.argmax(1)\n",
    "                translation_batch.append(trg_token.cpu().numpy())\n",
    "            \n",
    "            # Detokenize and collect examples\n",
    "            translation_batch = np.stack(translation_batch, axis=1)  # (batch_size, seq_len)\n",
    "            for i in range(batch_size):\n",
    "                src_text = detokenizers[SRC](src[i].cpu().tolist())\n",
    "                trg_text = detokenizers[TRG](trg[i].cpu().tolist())\n",
    "                pred_text = detokenizers[TRG](translation_batch[i].tolist())\n",
    "                examples.append((src_text, trg_text, pred_text))\n",
    "                \n",
    "                if len(examples) >= num_examples:\n",
    "                    break\n",
    "            if len(examples) >= num_examples:\n",
    "                break\n",
    "\n",
    "    # Print examples\n",
    "    for idx, (src_text, trg_text, pred_text) in enumerate(examples):\n",
    "        print(f\"Example {idx + 1}:\")\n",
    "        print(f\"Original English: {src_text}\")\n",
    "        print(f\"Original Urdu:    {trg_text}\")\n",
    "        print(f\"Predicted Urdu:   {pred_text}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# Display a few predictions\n",
    "display_predictions(model, dataloaders.test_loader, detokenizers, num_examples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T11:27:52.021681Z",
     "iopub.status.busy": "2024-11-17T11:27:52.021302Z",
     "iopub.status.idle": "2024-11-17T11:28:04.504841Z",
     "shell.execute_reply": "2024-11-17T11:28:04.503818Z",
     "shell.execute_reply.started": "2024-11-17T11:27:52.021645Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.45.1)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.0.1)\n",
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.18.3)\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: sacrebleu in /opt/conda/lib/python3.10/site-packages (2.4.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from wandb) (3.11.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.15.0)\n",
      "Requirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (70.0.0)\n",
      "Requirement already satisfied: portalocker in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (2.10.1)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.9.0)\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.4.6)\n",
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (5.3.0)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
      "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: evaluate\n",
      "Successfully installed evaluate-0.4.3\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets wandb evaluate sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T12:14:43.945515Z",
     "iopub.status.busy": "2024-11-17T12:14:43.945169Z",
     "iopub.status.idle": "2024-11-17T12:15:02.498971Z",
     "shell.execute_reply": "2024-11-17T12:15:02.494880Z",
     "shell.execute_reply.started": "2024-11-17T12:14:43.945483Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:32uzi3su) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f89a4ebc1d594e4baa5031f26e98f520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.025 MB of 0.025 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">crimson-fog-2</strong> at: <a href='https://wandb.ai/i210641-national-university-of-computers-and-emerging-sc/en-ur-translation-finetuning/runs/32uzi3su' target=\"_blank\">https://wandb.ai/i210641-national-university-of-computers-and-emerging-sc/en-ur-translation-finetuning/runs/32uzi3su</a><br/> View project at: <a href='https://wandb.ai/i210641-national-university-of-computers-and-emerging-sc/en-ur-translation-finetuning' target=\"_blank\">https://wandb.ai/i210641-national-university-of-computers-and-emerging-sc/en-ur-translation-finetuning</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241117_120739-32uzi3su/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:32uzi3su). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20241117_121443-xludhhpf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/i210641-national-university-of-computers-and-emerging-sc/en-ur-translation-finetuning/runs/xludhhpf' target=\"_blank\">tough-silence-3</a></strong> to <a href='https://wandb.ai/i210641-national-university-of-computers-and-emerging-sc/en-ur-translation-finetuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/i210641-national-university-of-computers-and-emerging-sc/en-ur-translation-finetuning' target=\"_blank\">https://wandb.ai/i210641-national-university-of-computers-and-emerging-sc/en-ur-translation-finetuning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/i210641-national-university-of-computers-and-emerging-sc/en-ur-translation-finetuning/runs/xludhhpf' target=\"_blank\">https://wandb.ai/i210641-national-university-of-computers-and-emerging-sc/en-ur-translation-finetuning/runs/xludhhpf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eba994b344f34ffdb4c681651ed9c7b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4117: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e51d0b529de043adac91171e9c7d5cc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/300 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 978.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 587.12 MiB is free. Process 3827 has 15.31 GiB memory in use. Of the allocated memory 14.94 GiB is allocated by PyTorch, and 68.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 211\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTranslation: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtranslation\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 211\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[24], line 186\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    183\u001b[0m val_processed \u001b[38;5;241m=\u001b[39m val_dataset\u001b[38;5;241m.\u001b[39mpreprocess_data()\n\u001b[1;32m    185\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[0;32m--> 186\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_processed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_processed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# Save fine-tuned model\u001b[39;00m\n\u001b[1;32m    189\u001b[0m trainer\u001b[38;5;241m.\u001b[39msave_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./final-mbart-en-ur-finetuned\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[24], line 159\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, tokenizer, train_dataset, val_dataset)\u001b[0m\n\u001b[1;32m    148\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Seq2SeqTrainer(\n\u001b[1;32m    149\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    150\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    155\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[1;32m    156\u001b[0m )\n\u001b[1;32m    158\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m--> 159\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trainer\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2052\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2050\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2051\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2052\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2054\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2055\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2056\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2057\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2388\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2385\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2387\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2388\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2391\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2392\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2393\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2394\u001b[0m ):\n\u001b[1;32m   2395\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2396\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:3518\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3516\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m   3517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3518\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3520\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:2192\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   2191\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2192\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2193\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m learning_rate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_lomo_optimizer:\n\u001b[1;32m   2194\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/graph.py:768\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    766\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 978.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 587.12 MiB is free. Process 3827 has 15.31 GiB memory in use. Of the allocated memory 14.94 GiB is allocated by PyTorch, and 68.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    MBartForConditionalGeneration,\n",
    "    MBart50TokenizerFast,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer,\n",
    "    DataCollatorForSeq2Seq\n",
    ")\n",
    "from datasets import Dataset as HFDataset\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import wandb\n",
    "import evaluate\n",
    "\n",
    "# Initialize wandb for experiment tracking\n",
    "wandb.init(project=\"en-ur-translation-finetuning\")\n",
    "\n",
    "# Constants\n",
    "MAX_LENGTH = 128\n",
    "BATCH_SIZE = 8\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_EPOCHS = 3\n",
    "WARMUP_STEPS = 500\n",
    "WEIGHT_DECAY = 0.01\n",
    "\n",
    "class TranslationDataset:\n",
    "    def __init__(self, src_texts, tgt_texts, tokenizer, max_length=MAX_LENGTH):\n",
    "        self.src_texts = src_texts\n",
    "        self.tgt_texts = tgt_texts\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        # Convert to HuggingFace dataset format\n",
    "        dataset_dict = {\n",
    "            'translation': [\n",
    "                {'en': src, 'ur': tgt} \n",
    "                for src, tgt in zip(self.src_texts, self.tgt_texts)\n",
    "            ]\n",
    "        }\n",
    "        dataset = HFDataset.from_dict(dataset_dict)\n",
    "        \n",
    "        # Tokenization function\n",
    "        def tokenize_function(examples):\n",
    "            en_texts = [ex['en'] for ex in examples['translation']]\n",
    "            ur_texts = [ex['ur'] for ex in examples['translation']]\n",
    "            \n",
    "            model_inputs = self.tokenizer(\n",
    "                en_texts,\n",
    "                max_length=self.max_length,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "\n",
    "            with self.tokenizer.as_target_tokenizer():\n",
    "                labels = self.tokenizer(\n",
    "                    ur_texts,\n",
    "                    max_length=self.max_length,\n",
    "                    padding='max_length',\n",
    "                    truncation=True,\n",
    "                    return_tensors=\"pt\"\n",
    "                )\n",
    "\n",
    "            model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "            return model_inputs\n",
    "\n",
    "        # Process dataset\n",
    "        tokenized_dataset = dataset.map(\n",
    "            tokenize_function,\n",
    "            batched=True,\n",
    "            remove_columns=dataset.column_names\n",
    "        )\n",
    "        \n",
    "        return tokenized_dataset\n",
    "\n",
    "def prepare_model_and_tokenizer():\n",
    "    \"\"\"Initialize pre-trained mBART model and tokenizer\"\"\"\n",
    "    model_name = \"facebook/mbart-large-50-many-to-many-mmt\"\n",
    "    \n",
    "    # Initialize tokenizer\n",
    "    tokenizer = MBart50TokenizerFast.from_pretrained(\n",
    "        model_name,\n",
    "        src_lang=\"en_XX\",\n",
    "        tgt_lang=\"ur_PK\"\n",
    "    )\n",
    "    \n",
    "    # Initialize model\n",
    "    model = MBartForConditionalGeneration.from_pretrained(model_name)\n",
    "    \n",
    "    return model, tokenizer\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"Compute BLEU and other metrics\"\"\"\n",
    "    metric = evaluate.load(\"sacrebleu\")\n",
    "    \n",
    "    predictions, labels = eval_pred\n",
    "    # Decode predicted tokens\n",
    "    predictions = self.tokenizer.batch_decode(\n",
    "        predictions, skip_special_tokens=True\n",
    "    )\n",
    "    \n",
    "    # Decode reference tokens\n",
    "    references = [[ref] for ref in tokenizer.batch_decode(\n",
    "        labels, skip_special_tokens=True\n",
    "    )]\n",
    "    \n",
    "    # Calculate BLEU score\n",
    "    result = metric.compute(\n",
    "        predictions=predictions,\n",
    "        references=references\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"bleu\": result[\"score\"],\n",
    "    }\n",
    "\n",
    "def train_model(model, tokenizer, train_dataset, val_dataset):\n",
    "    \"\"\"Fine-tune the model\"\"\"\n",
    "    \n",
    "    # Define training arguments\n",
    "    training_args = Seq2SeqTrainingArguments(\n",
    "        output_dir=\"./mbart-en-ur-finetuned\",\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        per_device_train_batch_size=BATCH_SIZE,\n",
    "        per_device_eval_batch_size=BATCH_SIZE,\n",
    "        num_train_epochs=NUM_EPOCHS,\n",
    "        weight_decay=WEIGHT_DECAY,\n",
    "        warmup_steps=WARMUP_STEPS,\n",
    "        save_total_limit=2,\n",
    "        predict_with_generate=True,\n",
    "        fp16=torch.cuda.is_available(),\n",
    "        logging_dir=\"./logs\",\n",
    "        logging_steps=100,\n",
    "        report_to=\"wandb\",\n",
    "    )\n",
    "\n",
    "    # Initialize data collator\n",
    "    data_collator = DataCollatorForSeq2Seq(\n",
    "        tokenizer,\n",
    "        model=model,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    # Initialize trainer\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        data_collator=data_collator,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "    \n",
    "    return trainer\n",
    "\n",
    "def main():\n",
    "    # Assuming train_set, valid_set, and test_set are already loaded\n",
    "    \n",
    "    # Initialize model and tokenizer\n",
    "    model, tokenizer = prepare_model_and_tokenizer()\n",
    "    \n",
    "    # Prepare datasets\n",
    "    train_dataset = TranslationDataset(\n",
    "        [pair[0] for pair in train_set],\n",
    "        [pair[1] for pair in train_set],\n",
    "        tokenizer\n",
    "    )\n",
    "    val_dataset = TranslationDataset(\n",
    "        [pair[0] for pair in valid_set],\n",
    "        [pair[1] for pair in valid_set],\n",
    "        tokenizer\n",
    "    )\n",
    "    \n",
    "    # Process datasets\n",
    "    train_processed = train_dataset.preprocess_data()\n",
    "    val_processed = val_dataset.preprocess_data()\n",
    "    \n",
    "    # Train model\n",
    "    trainer = train_model(model, tokenizer, train_processed, val_processed)\n",
    "    \n",
    "    # Save fine-tuned model\n",
    "    trainer.save_model(\"./final-mbart-en-ur-finetuned\")\n",
    "    \n",
    "    # Test model performance\n",
    "    def translate_text(text, tokenizer):\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", padding=True)\n",
    "        translated_tokens = model.generate(\n",
    "            **inputs,\n",
    "            max_length=MAX_LENGTH,\n",
    "            num_beams=5,\n",
    "            length_penalty=1.0,\n",
    "            early_stopping=True\n",
    "        )\n",
    "        return tokenizer.decode(translated_tokens[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Test on some examples\n",
    "    test_examples = [pair[0] for pair in test_set[:5]]\n",
    "    for text in test_examples:\n",
    "        translation = translate_text(text)\n",
    "        print(f\"Source: {text}\")\n",
    "        print(f\"Translation: {translation}\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T12:14:36.327048Z",
     "iopub.status.busy": "2024-11-17T12:14:36.326609Z",
     "iopub.status.idle": "2024-11-17T12:14:36.992310Z",
     "shell.execute_reply": "2024-11-17T12:14:36.991429Z",
     "shell.execute_reply.started": "2024-11-17T12:14:36.327003Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10794"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T12:26:14.964580Z",
     "iopub.status.busy": "2024-11-17T12:26:14.964170Z",
     "iopub.status.idle": "2024-11-17T12:26:23.214740Z",
     "shell.execute_reply": "2024-11-17T12:26:23.213584Z",
     "shell.execute_reply.started": "2024-11-17T12:26:14.964544Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MBartModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m _, tokenizer \u001b[38;5;241m=\u001b[39m prepare_model_and_tokenizer()\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mMBartModel\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/kaggle/working/mbart-en-ur-finetuned\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Test model performance\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtranslate_text\u001b[39m(text, tokenizer):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MBartModel' is not defined"
     ]
    }
   ],
   "source": [
    "_, tokenizer = prepare_model_and_tokenizer()\n",
    "model = MBartModel.from_pretrained(\"/kaggle/working/mbart-en-ur-finetuned\")\n",
    "\n",
    "# Test model performance\n",
    "def translate_text(text, tokenizer):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True)\n",
    "    translated_tokens = model.generate(\n",
    "        **inputs,\n",
    "        max_length=MAX_LENGTH,\n",
    "        num_beams=5,\n",
    "        length_penalty=1.0,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    return tokenizer.decode(translated_tokens[0], skip_special_tokens=True)\n",
    "\n",
    "# Test on some examples\n",
    "test_examples = [pair[0] for pair in test_set[:5]]\n",
    "for text in test_examples:\n",
    "    translation = translate_text(text, tokenizer)\n",
    "    print(f\"Source: {text}\")\n",
    "    print(f\"Translation: {translation}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6089676,
     "sourceId": 9911025,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
